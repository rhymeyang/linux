---
lang: zh-CN
title: Section 13.4 Containers
description: some description
---

As you study this section, answer the following questions:

<ul><li>What is the difference between virtual machines and containers?</li>
<li>What is a container?</li>
<li>What are some of the popular container management solutions?</li>
<li>What is a repository?</li>
<li>What does container orchestration mean?</li>
<li>What are some popular container orchestration engines?</li></ul>

In this section, you will learn to:

- Use containers
- Manage containers

The key terms for this section include:

<table class="terms">
<thead>
  <tr>
    <th>Term</th>
    <th>Definition</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Container</td>
    <td>
      An application isolated in a lightweight package that allows the
      user to use the program similar to how you would use a virtual
      machine.
    </td>
  </tr>
  <tr>
    <td>Container engine</td>
    <td>
      Similar to a hypervisor, a container engine is installed on top of
      the host operating system.
    </td>
  </tr>
  <tr>
    <td>Container orchestration</td>
    <td>
      Container orchestration is the process of automating, managing,
      scaling, and networking containers.
    </td>
  </tr>
</tbody>
</table>

This section helps you prepare for the following certification exam objectives:

<table class="objectives">
<thead>
  <tr>
    <th>Exam</th>
    <th>Objective</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>CompTIA Linux+ XK0-005</td>
    <td>
      3.2 Given a scenario, perform basic container operations
      <ul>
        <li>Container management</li>
        <ul>
          <li>Starting/stopping</li>
          <li>Inspecting</li>
          <li>Listing</li>
          <li>Deploying existing images</li>
          <li>Connecting to containers</li>
          <li>Logging</li>
          <li>Exposing ports</li>
        </ul>
        <li>Container image operations</li>
        <ul>
          <li>build</li>
          <li>push</li>
          <li>pull</li>
          <li>list</li>
          <li>rmi</li>
        </ul>
      </ul>
      <p>3.5 Summarize container, cloud, and orchestration concepts</p>
      <ul>
        <li>Kubernetes benefits and application use cases</li>
        <ul>
          <li>Pods</li>
          <li>Sidecars</li>
          <li>Ambassador containers</li>
        </ul>
        <li>
          Container networks
          <ul>
            <li>Overlay networks</li>
            <li>Bridging</li>
            <li>Network address translation (NAT)</li>
            <li>Host</li>
          </ul>
        </li>
        <li>Service mesh</li>
        <li>Bootstrapping</li>
        <li>Container registries</li>
      </ul>
    </td>
  </tr>
</tbody>
</table>

## 13.4.1 Containers on Linux

Click one of the buttons to take you to that part of the video.

Containers 00:00-00:14
In this video, we're going to take a look at how containers work. You may hear the word Docker when the subject of containers comes up. Docker is software that's used to create, manage, and distribute containers.

Virtual Machines vs Containers 00:14-00:49
Containers are commonly compared to virtual machines. Like virtual machines, they have a base hardware and operating system.

These physical devices have all the components that make a computer work: a processor, RAM, Hard Drive, input devices, and a graphical user interface, or GUI.

When you create a virtual machine, you allocate a portion of your hardware resources to run another

virtual computer within your system, often with a GUI of its own. This can become very difficult to support and manage. As you create more virtual machines, you end use more resources.

How Containers Work 00:49-01:45
Containers help with this problem. Instead of creating a separate virtual machine for each program or service you want to run, ye create a minimalistic environment built for a dedicated task. This environment only has the software libraries and packages needed to run the intended software, nothing else. You get the same individualized and isolated environment you do with a virtual machine, but without having to allocate large portions of your hardware to utilize it.

Let's take a closer look at this setup. With containers, we have our system hardware. This is what all the software will run on, of course. We install the Linux Operating System on top of our hardware. Then we install container software, like Docker, which aids in downloading, initializing, and managing our containers. Finally, we run our intended software via containers.

When we compare our running our applications in a container environment to a virtual machine environment, we see that containers can utilize less resources.

Parts of a container 01:45-02:23
A container consists of three parts. We have the software that's used to download, run, and manage containers. This is software such as Docker. Next is a container image. This is an image of the intended application. Think of it as a software package you download from the internet. This image will have all the necessary parts for the containerized application to run.

The final piece is the actual application container. The container software will use the container image to build the container from a base OS and initialize the intended application. This process may seem difficult, but it's fairly simple, like downloading and installing software.

Container Pros 02:23-03:03
Containers have several key benefits. They allow developers to package applications with all needed dependencies. This includes prerequisite software and libraries. Then they can distribute the application in one image.

Containers provide consistent environments. The applications within containers are built from the ground up. The developer creates the base OS, libraries, resources, and application. This makes implementation and troubleshooting easier.

Containers are portable. Since they run independent of the host machine, they can be backed up and moved as needed. Overall, containers have proven to be an extremely effective tool in the technology industry.

Summary 03:03-03:18
In this lesson, we compared containers and virtual machines. We looked at how the two technologies approach creating independent environments, and we discussed the functions and benefits of containers.

## 13.4.2 Using Containers

Click one of the buttons to take you to that part of the video.

Containers 00:00-00:32
We're going to review how to use containers. Containers are self-contained packages of software. Similar to a virtual machine, they allow users to run virtualized environments. However, the virtual environment for a container is only built with the items necessary to run the intended container package.

In most cases, an entire operating system isn't needed. There's no need for a graphical environment or other tools built into operating systems. Containers are predictable environments that are isolated from all other applications.

Let's begin with Docker images.

Docker Images 00:32-01:20
An image is a prepackaged set of instructions used to build containers. They begin with a base operating system and have software packages, configurations, and files built on top. Think of them as executable installers for Windows. Just because the image is downloaded on the computer doesn't mean the software is installed. Let's run docker images, and we see that we currently don't have any images on this system.

We pull images from repositories. Docker comes preconfigured to pull images from the online Docker repositories. Let's run docker pull Nginx. Once complete, run docker pull ubuntu. When we rerun the Docker images command, we see that both ubuntu and Nginx are downloaded to the system.

Docker Containers 01:20-02:40
Now that we have images ready let's create the containers. This could be equated to installing software. We type docker create --name test_container ubuntu. We're creating a container. The --name option allows us to give the container an easy-to-remember name. Otherwise, Docker will create a random name for the container, or we'll need to identify the container by an ID number. Lastly, we instruct Docker to use the ubuntu image when creating the container.

Let's view our new container. Run docker ps to list containers on the system. We don't see any containers listed on the system. The ps command only shows running or in-use containers. The -a option is needed to show all containers. Let's run docker ps -a, and we see that our container is listed and its status is Created.

Run docker start test_container to start the container. Let's rerun docker ps. We still don't see the container in the list. When we run docker ps -a, we see the status as Exited.

When we start a container, there's coding that runs from the image. If the image isn't programmed to complete a task, return output or keep running. The container will power on, run the code, and then exit. There are options that we must use with the start command in order to keep the container running.

Connecting to Containers 02:40-04:13
Instead of using the create and start command, most users will use the Docker run command. Docker run completes three tasks instead of one. It will pull an image if there isn't one on the system already. It will create the container, and it will start the container.

Let's type docker run --name centos_container -i -t centos:7. The name option allows us to use an easy-to-remember name in lieu of an ID number or randomly generated name. The -i option is short for interactive, and the -t option stands for TTY. This'll keep the container running and keep shell access available to configure or modify the container. Centos:7 is the name and version of the base operating system image we want the container to run.

Press Enter. The Docker run command will pull the latest CentOS 7 image from the online Docker repository, create the container, start the container, and drop us in a shell. We see that the shell prompt has changed as well as our hostname. We're now in the CentOS 7 environment within the container.

Container images are known as base images. They're bare-bones versions of our operating systems. Let's try running the netstat command. Enter netstat, and we see a command not found error. Let's run yum install net-tools and run the netstat command again. We now see the output for the netstat command.

We exit the container shell just as we do ssh sessions. Type exit, and we're returned to our host system shell.

Creating Images 04:13-05:28
When we make changes to a container, they can be saved to a new image. This is how new container software images are created. A base image is pulled, and software is installed, configured, or created. Then we write the container to a new image file.

The Docker commit command is used to make images from containers. To run this command, we need the container ID. Thankfully, the hostname of our container and the container ID are the same. To create an image of CentOS 7 with the netstat command preinstalled, run docker commit [image name] net-tools-centos.

We can run the new image just as we did the CentOS one. Type docker run --name custom-image -dit net-tools-centos. The d stands for detach. This'll allow us to run the container in the background without immediately interacting with the shell. When we run docker ps, we see only the new container we created from our custom image. Its status is up. When we run docker ps -a, we see the three containers we've used in this session: the ubuntu that was our first test container, the centos container that we installed net-tools on originally, and the custom-image container we created from our custom image.

Logging in Containers 05:28-05:55
We can view the logs of our containers with the Docker logs command. Run docker logs and the container name centos_container. We see output from our earlier shell session. Let's rerun the command, but this time on our custom-image container. Nothing loads because we haven't interacted with that container yet.

Containers will only log information that has changed since the initial image deployment. Since this image was made with net-tools installed, there are no logs to show.

Stopping Containers 05:55-06:14
Lastly, let's look at stopping containers that are running or have a status of up. The command is Docker stop plus the container name. Right now, we know the only container running is our custom-image container. Let's run docker stop custom-image and list all containers again. We see the container is in an Exited status.

Summary 06:14-06:23
In this demonstration, we learned how to pull, run, and create Docker containers.

## 13.4.3 Managing Containers

Click one of the buttons to take you to that part of the video.

Containers 00:00-00:17
In this demo, we're going to look at managing containers on a system. If we leave exited containers on a system, that can fill hard disk space quickly. There may also be times when we need to inspect containers for configurations.

Inspect Containers 00:17-02:27
Let's run docker images. This system doesn't have any images ready to work with. Let's pull an nginx image. Nginx is a webserver. This image will install a container that will run a webserver for my system. We need to inspect the image to see which port the webserver will run on.

The docker inspect command can provide detailed information about the properties of a docker image. Let's run docker image inspect nginx. This brings up a lot of information. We can use the -f option to search for a field of information, similar to the grep command. Let's type docker image inspect nginx -f '{{ .ContainerConfig.ExposedPorts }}' The inspect command defaults to searching and displaying in JSON arrays. We're searching the image for a container configuration that will show us which port is exposed for any containers built from the image. We see that this is a regular nginx installation that defaults to port 80, http traffic.

To make this webserver container operational, we need to start the container and provide a bridge between it and the physical system. To do this, we run docker run --name nginx-test -d -P nginx. The -d option runs the container in the background. The -P option will publish all exposed ports to random ports. This means that port 80 on my container will bridge to a random port on my system. When users try to access the webserver, they'll access my system IP address and the randomly generated port number. My system will take traffic on that port number and pass it to the container on port 80.

First, run ip a and get the IP address of the system. Then open a web browser and navigate to that IP. We see that nothing loads. Let's run docker ps -a to view which port number was assigned to the nginx container. We'll add the port number to the address bar, and we see the nginx landing page.

Build Images 02:27-04:07
Okay, now let's talk about building images. It's a useful option, but it can bloat the size of containers. It's more common to create a build file that will take a base OS image and run commands and other instructions to create the image.

Let's make a directory named build_test and cd into it. Next, create a build file that's named Dockerfile and enter a text editor. You begin by adding comments detailing your commands. Type #set the base image. On a new line, enter FROM in all caps and ubuntu in lowercase.

The next line will have #author, and we'll enter MAINTAINER TestOut on another line. You would type your own name or your company's name for the author. Next, we add #Metadata. Then type LABEL version="1.0"' and LABEL description="Building an image with a Dockerfile" on separate lines. Lastly, we'll add a comment detailing package management. Then type RUN apt clean, RUN apt update, and RUN apt install cowsay -y on separate lines. Once that's done, write the file and exit the editor. Our build file is ready.

Now let's type docker build -t jmacetestout/testout_image:cowsay . The -t option allows us to tag the image to make it identifiable to other users. In order to properly tag an image, you must have a docker hub account to associate the tags with. Run docker images to see the newly built docker image listed.

Push Docker Images 04:07-04:45
The next step is to share images with others. The most common way to do this is to push the images to the online docker repository using the docker push command. You must have a docker hub account and be logged in to docker.

To log in to docker, run docker login and provide your login information. Once we're logged in, we can push the build image we just created with docker push and your docker hub usersname, then /testout_image:cowsay. The text after the forward slash (/) is the name you want to give the image. The text after the colon consists of tags that can be used to identify and quickly search for your image in the docker repository.

Clean Unused Containers and Images 04:45-05:44
Lastly, as we work, we'll want to remove containers and images that are no longer in use. To remove a container, it must be inactive or exited. If you want to remove an image, it must not have a container, active or inactive, loaded from it.

Let's list all our containers. We need to stop the nginx container with docker stop nginx-test. Now we can use the docker rm command to remove the container. Let's run docker rm nginx-test. When we run docker ps -a again, we see that all containers are removed.

The command to remove images is similar to removing containers. Let's run docker images. We see three images pulled to our system: our new build image, nginx, and ubuntu. To remove these images, we'll run docker rmi and the image ID of our custom build image, nginx ubuntu. When we run docker images again, we can see that all images have been removed.

Summary 05:44-06:04
And that's all for this demo on managing containers. We discussed how to inspect docker images, publish ports within a container, build custom images with a Dockerfile script, push images to the docker repository, and remove unnecessary containers and images from a system.

## 13.4.4 Container Facts

This lesson covers the following topics:

<ul><li>Virtual machines vs. containers</li>
<li>Container management</li>
<li>Container image operations</li>
<li>Summarizing orchestration concepts</li></ul>

### Virtual Machines vs. Containers

Containers are a way to run programs in a virtual environment. Containers include all the files, libraries, and even any necessary operating system files that might be needed, bundled into one package. Containers use the same principle as virtual machines. They are installed on top of the operating system with an abstraction layer to share resources between the hardware and the containers.

The following table lists common terms you should be familiar with when working with containers:

<table>
<thead>
  <tr>
    <th>Term</th>
    <th>Definition</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Virtual machine</td>
    <td>
      A virtual machine uses physical resources like the CPU, memory, and
      hard drive to run an operating system from within its host.
    </td>
  </tr>
  <tr>
    <td>Hypervisor</td>
    <td>
      On a server, the hypervisor is installed on top of the hardware of a
      server and virtualizes all the hardware resources to different
      clients in the form of an operating system.
    </td>
  </tr>
  <tr>
    <td>Container engine</td>
    <td>
      Instead of installing the hypervisor on top of the hardware, the
      container engine is installed on top of the host operating system.
      This allows the containers to use the resources from the host
      operating system.
    </td>
  </tr>
  <tr>
    <td>Container</td>
    <td>
      An application isolated in a lightweight package that allows the
      user to use the program similar to how you would use a virtual
      machine.
    </td>
  </tr>
  <tr>
    <td>Container management</td>
    <td>
      Because of their size, many individual containers can exist on one
      operating system. To help manage these containers, you can use
      either Docker or Podman.
    </td>
  </tr>
</tbody>
</table>

### Container Management

Containers are managed by software, much like a hypervisor manages virtual machines. Docker and Podman are two popular solutions.

### Docker:

Docker is a lightweight package that was created by Docker Inc. and released as open source. Docker runs on top of a host system, such as Linux. Some facts about Docker and managing Docker are:

<ul>
<li>Docker runs as the root user.</li>
<li>Docker is used to build and manage container images.</li>
<li>
  Docker is monolithic in architecture, meaning that it is independent and
  self-contained.
</li>
<li>
  Once a container is deployed in Docker, it can be stopped and started by
  using the <b class="fw-bold">docker start</b> and
  <b class="fw-bold">docker stop</b> commands.
</li>
<li>
  To inspect and gather detailed information about a container in Docker,
  use the <b class="fw-bold">docker inspect</b> command. This command will
  produce a lot of information. It's recommended to output the contents
  and use <b class="fw-bold">grep</b> to inspect the information.
</li>
<li>
  To list all the containers in Docker, use the
  <b class="fw-bold">docker ps</b> command. This command will list
  contents in columns and will include, container ID, name of image,
  command used to start container, when the container was started, current
  status of container, ports used, and name.
</li>
<li>
  Docker images are deployed using the command:
  <b class="fw-bold">docker run -name</b>
  <i class="fs-italicize">NAME</i> <b class="fw-bold">-p</b>
  <i class="fs-italicize">PORTS IMAGE.</i> NAME is the name of the
  container, PORTS is the port your want to expose, IMAGE is the name of
  the image.
</li>
<li>
  Connecting to running containers is done by using the
  <b class="fw-bold">docker exec</b> command in the Docker image. Type
  <b class="fw-bold">exit</b> to break the connection.
</li>
<li>
  To view logs of a container, use the
  <b class="fw-bold">docker log</b> command.
</li>
</ul>

### Podman:

Podman is a tool and is considered daemonless, which is the main difference from Docker. It is open-source that is used to find, run, build, share, and deploy applications on Linux systems. Some facts about Podman are:

<ul>
<li>Podman can run rootless.</li>
<li>
  Podman can not be used to build images. A separate tool called Buildah
  is needed. Another tool, Skopeo, moves container images between
  different types of storage systems.
</li>
<li>Podman is modular.</li>
<li>Podman uses a command line interface.</li>
</ul>

### Container Image Operations

You are able to build and create your own images. You can also find existing container images in repositories . When working with your images, you will use operations to store and retrieve images. Keep in mind the following facts about container image operations.

<ul>
<li>
  To build your own Docker image, you can use a Dockerfile. A Dockerfile
  is a text file that has instructions that tell Docker what to do when
  creating an image. The text file will detail the parent image and
  initial state where it should start. It will contains metadata about the
  author and properties of the image. Will contain the commands to run
  during the build. Specify details about the image that will be created.
</li>
<li>
  When you want an image to be stored in a repository, you
  <b class="fw-bold">push</b> the image. Pushing an image is the process
  of copying it from your local machine to the repository. Pushing can be
  done from a command line or from a program designed to do so. Images are
  often tagged with the latest version during the push process.
</li>
<li>
  Pulling an image is the reverse process of pushing. You
  <b class="fw-bold">pull</b> an image when you want to bring the current
  version to your local machine.
</li>
<li>
  To view a list of Docker images on your system, use the
  <b class="fw-bold">docker images</b> command or
  <b class="fw-bold">docker image ls</b> command.
</li>
<li>
  You can remove Docker images with the
  <b class="fw-bold">docker rmi</b> command.
</li>
</ul>

### Summarizing Orchestration Concepts

As a review, containers are a way to run programs in a virtual environment. Containers include all the files, libraries, and even any necessary operating system files that might be needed, bundled into one package. Once you have many containers, you need a way to manage them. This is where the term orchestration comes in. Container orchestration is the process of automating, managing, scaling, and networking containers. There are several orchestration engines that can be used for this, including Docker Swarm, Apache Mesos, and Kubernetes. It's important to note that sometimes automation and orchestration are confused with each others. Automation is typically used to automate a single task to reduce the manual interaction by a human. Orchestration is the process of automating processes and workflows that involves many different tasks and many different systems.

The following table lists and compares some of these orchestration engines:

<table>
  <thead>
    <tr>
      <th>Orchestration Engine</th>
      <th>Concepts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td width="151">Kubernetes</td>
      <td width="1384">
        Kubernetes is an open-source orchestration system. Kubernetes was
        originally created by Google, but is now maintained by the Cloud
        Native Computing Foundation. Most consider Kubernetes the gold
        standard in orchestration systems. Below are some facts about
        Kubernetes.
        <ul>
          <li>Works with Docker, Containerd, and CRI-O.</li>
          <li>
            Monitors the health of containers and responds if the containers
            are not responding or performing poorly.
          </li>
          <li>Can run multiple containers at the same time.</li>
          <li>Works with on-premises or cloud systems.</li>
          <li>Can by used for load balancing.</li>
          <li>
            Is highly scalable, meaning that you can add more containers if
            needed.
          </li>
          <li>
            Can be used to manage updates, including rolling back updates.
          </li>
        </ul>
        <p>Several key concepts used by Kubernetes are:</p>
        <ul>
          <li>
            With Kubernetes, you can use what are referred to as
            <i class="fs-italicize">pods</i> . Pods are a group of
            containers when resources are shared. The shared recourse could
            be something like a storage pool. The pods are all able to
            access the same storage.
          </li>
          <li>
            Using the above storage example, if you need to make changes to
            the storage, you can use just one of the Kubernetes containers
            in the pod to do so. This container is referred to as a
            <i class="fs-italicize">sidecar</i> .
          </li>
          <li>
            Sidecars are containers used to perform a task on behalf of
            other containers. We can refer to this sidecar as an
            <i class="fs-italicize">Ambassador containe</i> r, meaning that
            this container is sort of the spokesperson for all the
            containers in the pod. Remember, we want containers to focus on
            one task, so having a dedicated container to perform tasks such
            as communication with other containers is considered best
            practice.
          </li>
          <li>
            We know that containers are used typically to perform one task.
            Sometimes, to perform a series of tasks requirement multiple
            containers, each doing something different. When these
            containers are combined into pods, this is referred to as
            <i class="fs-italicize">microservices</i> . When microsservices
            need to work together, it's referred to as a
            <i class="fs-italicize">service mesh</i> . Finally, the service
            mesh is established by using sidecars.
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td width="151">Docker Swarm</td>
      <td width="1384">
        Docker Swarm is used to cluster Docker containers. In general, a
        swarm is to move something in large numbers. Docker Swarm:
        <ul>
          <li>Is integrated with Docker.</li>
          <li>
            Uses a command line interface to manage the containers in the
            swarm.
          </li>
          <li>Allows scaling of the swarm.</li>
          <li>Can be used for load balancing.</li>
          <li>Allows for rolling out updates.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td width="151">Apache Mesos</td>
      <td width="1384">
        Apache Mesos is used to manage computer clusters. Apache Mesos was
        developed by the University of Berkeley and is open source. Apache
        Mesos:
        <ul>
          <li>
            Is a container management tool used to isolate CPU, memory, and
            file systems on Linux systems.
          </li>
          <li>Can run Hadoop, Jenkins, Spark, Aurora, and other tools.</li>
          <li>
            Is combined with Marathon to provide a more complete solution to
            orchestration.
          </li>
          <li>Can be used to manage Docker containers.</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

We have summarized some of the specific features for orchestration engines. The following table lists other orchestration terms and concepts:

<table>
<thead>
  <tr>
    <th>Term</th>
    <th>Definition</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td width="151">Single-node and multi-node uses</td>
    <td width="1384">
      With Kubernetes, you use pods to combine containers to work together
      to handle tasks as we scale. A use case example of when this happens
      is a website that handles all the web traffic for your business. One
      day, your business becomes very popular, and you need to add more
      containers to handle the traffic. This is a simple example of when
      we went from having a single container, or node, to a pod of
      containers (multi-node).
    </td>
  </tr>
  <tr>
    <td width="151">Container persistent storage</td>
    <td width="1384">
      In general, persistent storage is a physical storage on a device
      such as a traditional hard drive or a solid-state drive. It is
      called persistent because the data on the devices is retained if the
      devices lose power. By default, containers do not save the data that
      they produce. When a container loses power, the data is lost, so
      this is a major concern for containers that need to store data. When
      containers need to store data, they have to be configured to store
      the data on a back-end storage system. These systems can be local
      storage that are mounted. The underlining devices can be a variety
      of solutions, such as traditional sata drives, solid-state drives,
      RAID arrays, or storage area networks.
    </td>
  </tr>
  <tr>
    <td width="151">Container networks</td>
    <td width="1384">
      Traditional methods of networking involves having a network card on
      a device that communicates with other nodes on a network or the
      internet. Containers and the applications that run on them will most
      often need access to the network or to the internet. With
      containers, networks work a bit differently than traditional
      networking. A few key container networking concepts are:
      <ul>
        <li>
          Overlay networks work by using tunnels to talk to other
          containers on a network. This will allow containers to function
          as if they are located on the same host.
        </li>
        <li>
          Bridging is the establishment of different network segments
          together. This is typically done by directing traffic through
          routers. But with bridging, the segments are merged into a
          single segment. There are different types of bridging: simple
          bridging merges two segments, multiport merges multiple
          networks, transparent bridging builds routing tables, and source
          route builds route based on the source.
        </li>
        <li>
          Network address translation (NAT) is the process of translating
          private IP addresses into public IP addresses. This concept is
          no different than how it is done traditionally. Some of the
          types of NAT used with container networking are DNAT, SNAT, and
          Masquerade NAT.
        </li>
        <ul>
          <li>
            DNAT, or destination NAT, is used when servers are behind
            firewalls, and you want to access them from the internet.
          </li>
          <li>
            SNAT, or source NAT, is used when internal networks are using
            statically assigned IP addresses. Traffic is directed to the
            internet through device with a access to the internet.
          </li>
          <li>
            Masquerade Nat is used in internal networks with dynamic IP
            addressing. Traffic to the public internet is directed through
            a single device.
          </li>
        </ul>
        <li>
          Often times, your container will only need to communicate with
          the host that it resides on. If outside communication is needed
          to reach the container, it will be configured to flow through
          the host through a virtual network connection.
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td width="151">Bootstrapping</td>
    <td width="1384">
      Bootstrapping is the process to self-start without assistance. In
      computing, the term <i class="fs-italicize">booting</i> refers to a
      system starting up when it receives power via the bootloader code.
      Bootstrapping refers to installing a new system from an image or
      configuration from an existing system through automation. A tool
      that can be used to do this is called Cloud-int. Cloud-int can be
      used to configure networking, run scripts, and other tasks.
    </td>
  </tr>
  <tr>
    <td width="151">Container registries</td>
    <td width="1384">
      Container registries or container repositories are a central
      location where container images are stored. Examples are Docker Hub,
      Amazon ECR, Harbor, GitHub Container Registry, and Google Container
      Registry.
    </td>
  </tr>
</tbody>
</table>
