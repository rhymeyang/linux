import{_ as t,c as n,a,o as i}from"./app-D-CuBheB.js";const o={};function s(r,e){return i(),n("div",null,e[0]||(e[0]=[a('<p>As you study this section, answer the following questions:</p><ul><li>What is the difference between virtual machines and containers?</li><li>What is a container?</li><li>What are some of the popular container management solutions?</li><li>What is a repository?</li><li>What does container orchestration mean?</li><li>What are some popular container orchestration engines?</li></ul><p>In this section, you will learn to:</p><ul><li>Use containers</li><li>Manage containers</li></ul><p>The key terms for this section include:</p><table class="terms"><thead><tr><th>Term</th><th>Definition</th></tr></thead><tbody><tr><td>Container</td><td> An application isolated in a lightweight package that allows the user to use the program similar to how you would use a virtual machine. </td></tr><tr><td>Container engine</td><td> Similar to a hypervisor, a container engine is installed on top of the host operating system. </td></tr><tr><td>Container orchestration</td><td> Container orchestration is the process of automating, managing, scaling, and networking containers. </td></tr></tbody></table><p>This section helps you prepare for the following certification exam objectives:</p><table class="objectives"><thead><tr><th>Exam</th><th>Objective</th></tr></thead><tbody><tr><td>CompTIA Linux+ XK0-005</td><td> 3.2 Given a scenario, perform basic container operations <ul><li>Container management</li><ul><li>Starting/stopping</li><li>Inspecting</li><li>Listing</li><li>Deploying existing images</li><li>Connecting to containers</li><li>Logging</li><li>Exposing ports</li></ul><li>Container image operations</li><ul><li>build</li><li>push</li><li>pull</li><li>list</li><li>rmi</li></ul></ul><p>3.5 Summarize container, cloud, and orchestration concepts</p><ul><li>Kubernetes benefits and application use cases</li><ul><li>Pods</li><li>Sidecars</li><li>Ambassador containers</li></ul><li> Container networks <ul><li>Overlay networks</li><li>Bridging</li><li>Network address translation (NAT)</li><li>Host</li></ul></li><li>Service mesh</li><li>Bootstrapping</li><li>Container registries</li></ul></td></tr></tbody></table><h2 id="_13-4-1-containers-on-linux" tabindex="-1"><a class="header-anchor" href="#_13-4-1-containers-on-linux"><span>13.4.1 Containers on Linux</span></a></h2><p>Click one of the buttons to take you to that part of the video.</p><p>Containers 00:00-00:14 In this video, we&#39;re going to take a look at how containers work. You may hear the word Docker when the subject of containers comes up. Docker is software that&#39;s used to create, manage, and distribute containers.</p><p>Virtual Machines vs Containers 00:14-00:49 Containers are commonly compared to virtual machines. Like virtual machines, they have a base hardware and operating system.</p><p>These physical devices have all the components that make a computer work: a processor, RAM, Hard Drive, input devices, and a graphical user interface, or GUI.</p><p>When you create a virtual machine, you allocate a portion of your hardware resources to run another</p><p>virtual computer within your system, often with a GUI of its own. This can become very difficult to support and manage. As you create more virtual machines, you end use more resources.</p><p>How Containers Work 00:49-01:45 Containers help with this problem. Instead of creating a separate virtual machine for each program or service you want to run, ye create a minimalistic environment built for a dedicated task. This environment only has the software libraries and packages needed to run the intended software, nothing else. You get the same individualized and isolated environment you do with a virtual machine, but without having to allocate large portions of your hardware to utilize it.</p><p>Let&#39;s take a closer look at this setup. With containers, we have our system hardware. This is what all the software will run on, of course. We install the Linux Operating System on top of our hardware. Then we install container software, like Docker, which aids in downloading, initializing, and managing our containers. Finally, we run our intended software via containers.</p><p>When we compare our running our applications in a container environment to a virtual machine environment, we see that containers can utilize less resources.</p><p>Parts of a container 01:45-02:23 A container consists of three parts. We have the software that&#39;s used to download, run, and manage containers. This is software such as Docker. Next is a container image. This is an image of the intended application. Think of it as a software package you download from the internet. This image will have all the necessary parts for the containerized application to run.</p><p>The final piece is the actual application container. The container software will use the container image to build the container from a base OS and initialize the intended application. This process may seem difficult, but it&#39;s fairly simple, like downloading and installing software.</p><p>Container Pros 02:23-03:03 Containers have several key benefits. They allow developers to package applications with all needed dependencies. This includes prerequisite software and libraries. Then they can distribute the application in one image.</p><p>Containers provide consistent environments. The applications within containers are built from the ground up. The developer creates the base OS, libraries, resources, and application. This makes implementation and troubleshooting easier.</p><p>Containers are portable. Since they run independent of the host machine, they can be backed up and moved as needed. Overall, containers have proven to be an extremely effective tool in the technology industry.</p><p>Summary 03:03-03:18 In this lesson, we compared containers and virtual machines. We looked at how the two technologies approach creating independent environments, and we discussed the functions and benefits of containers.</p><h2 id="_13-4-2-using-containers" tabindex="-1"><a class="header-anchor" href="#_13-4-2-using-containers"><span>13.4.2 Using Containers</span></a></h2><h3 id="containers-00-00-00-32" tabindex="-1"><a class="header-anchor" href="#containers-00-00-00-32"><span>Containers 00:00-00:32</span></a></h3><p>We&#39;re going to review how to use containers. Containers are self-contained packages of software. Similar to a virtual machine, they allow users to run virtualized environments. However, the virtual environment for a container is only built with the items necessary to run the intended container package.</p><p>In most cases, an entire operating system isn&#39;t needed. There&#39;s no need for a graphical environment or other tools built into operating systems. Containers are predictable environments that are isolated from all other applications.</p><p>Let&#39;s begin with Docker images.</p><h3 id="docker-images-00-32-01-20" tabindex="-1"><a class="header-anchor" href="#docker-images-00-32-01-20"><span>Docker Images 00:32-01:20</span></a></h3><p>An image is a prepackaged set of instructions used to build containers. They begin with a base operating system and have software packages, configurations, and files built on top. Think of them as executable installers for Windows. Just because the image is downloaded on the computer doesn&#39;t mean the software is installed. Let&#39;s run docker images, and we see that we currently don&#39;t have any images on this system.</p><p>We pull images from repositories. Docker comes preconfigured to pull images from the online Docker repositories. Let&#39;s run docker pull Nginx. Once complete, run docker pull ubuntu. When we rerun the Docker images command, we see that both ubuntu and Nginx are downloaded to the system.</p><h3 id="docker-containers-01-20-02-40" tabindex="-1"><a class="header-anchor" href="#docker-containers-01-20-02-40"><span>Docker Containers 01:20-02:40</span></a></h3><p>Now that we have images ready let&#39;s create the containers. This could be equated to installing software. We type <code>docker create --name test_container ubuntu</code>. We&#39;re creating a container. The <code>--name</code> option allows us to give the container an easy-to-remember name. Otherwise, Docker will create a random name for the container, or we&#39;ll need to identify the container by an ID number. Lastly, we instruct Docker to use the ubuntu image when creating the container.</p><p>Let&#39;s view our new container. Run docker ps to list containers on the system. We don&#39;t see any containers listed on the system. The ps command only shows running or in-use containers. The <code>-a</code> option is needed to show all containers. Let&#39;s run <code>docker ps -a</code>, and we see that our container is listed and its status is Created.</p><p>Run docker start test_container to start the container. Let&#39;s rerun <code>docker ps</code>. We still don&#39;t see the container in the list. When we run <code>docker ps -a</code>, we see the status as Exited.</p><p>When we start a container, there&#39;s coding that runs from the image. If the image isn&#39;t programmed to complete a task, return output or keep running. The container will power on, run the code, and then exit. There are options that we must use with the start command in order to keep the container running.</p><h3 id="connecting-to-containers-02-40-04-13" tabindex="-1"><a class="header-anchor" href="#connecting-to-containers-02-40-04-13"><span>Connecting to Containers 02:40-04:13</span></a></h3><p>Instead of using the create and start command, most users will use the Docker run command. Docker run completes three tasks instead of one. It will pull an image if there isn&#39;t one on the system already. It will create the container, and it will start the container.</p><p>Let&#39;s type <code>docker run --name centos_container -i -t centos:7</code>. The name option allows us to use an easy-to-remember name in lieu of an ID number or randomly generated name. The <code>-i</code> option is short for interactive, and the <code>-t</code> option stands for TTY. This&#39;ll keep the container running and keep shell access available to configure or modify the container. Centos:7 is the name and version of the base operating system image we want the container to run.</p><p>Press Enter. The Docker run command will pull the latest CentOS 7 image from the online Docker repository, create the container, start the container, and drop us in a shell. We see that the shell prompt has changed as well as our hostname. We&#39;re now in the CentOS 7 environment within the container.</p><p>Container images are known as base images. They&#39;re bare-bones versions of our operating systems. Let&#39;s try running the netstat command. Enter netstat, and we see a command not found error. Let&#39;s run <code>yum install net-tools</code> and run the <code>netstat</code> command again. We now see the output for the netstat command.</p><p>We exit the container shell just as we do ssh sessions. Type exit, and we&#39;re returned to our host system shell.</p><h3 id="creating-images-04-13-05-28" tabindex="-1"><a class="header-anchor" href="#creating-images-04-13-05-28"><span>Creating Images 04:13-05:28</span></a></h3><p>When we make changes to a container, they can be saved to a new image. This is how new container software images are created. A base image is pulled, and software is installed, configured, or created. Then we write the container to a new image file.</p><p>The Docker commit command is used to make images from containers. To run this command, we need the container ID. Thankfully, the hostname of our container and the container ID are the same. To create an image of CentOS 7 with the netstat command preinstalled, run <code>docker commit [image name] net-tools-centos</code>.</p><p>We can run the new image just as we did the CentOS one. Type <code>docker run --name custom-image -dit net-tools-centos</code>. The <code>d</code> stands for detach. This&#39;ll allow us to run the container in the background without immediately interacting with the shell. When we run <code>docker ps</code>, we see only the new container we created from our custom image. Its status is up. When we run <code>docker ps -a</code>, we see the three containers we&#39;ve used in this session: the ubuntu that was our first test container, the centos container that we installed <code>net-tools</code> on originally, and the custom-image container we created from our custom image.</p><h3 id="logging-in-containers-05-28-05-55" tabindex="-1"><a class="header-anchor" href="#logging-in-containers-05-28-05-55"><span>Logging in Containers 05:28-05:55</span></a></h3><p>We can view the logs of our containers with the <code>Docker logs</code> command. Run <code>docker logs</code> and the container name centos_container. We see output from our earlier shell session. Let&#39;s rerun the command, but this time on our custom-image container. Nothing loads because we haven&#39;t interacted with that container yet.</p><p>Containers will only log information that has changed since the initial image deployment. Since this image was made with net-tools installed, there are no logs to show.</p><h3 id="stopping-containers-05-55-06-14" tabindex="-1"><a class="header-anchor" href="#stopping-containers-05-55-06-14"><span>Stopping Containers 05:55-06:14</span></a></h3><p>Lastly, let&#39;s look at stopping containers that are running or have a status of up. The command is Docker stop plus the container name. Right now, we know the only container running is our custom-image container. Let&#39;s run docker stop custom-image and list all containers again. We see the container is in an Exited status.</p><h3 id="summary-06-14-06-23" tabindex="-1"><a class="header-anchor" href="#summary-06-14-06-23"><span>Summary 06:14-06:23</span></a></h3><p>In this demonstration, we learned how to pull, run, and create Docker containers.</p><h2 id="_13-4-3-managing-containers" tabindex="-1"><a class="header-anchor" href="#_13-4-3-managing-containers"><span>13.4.3 Managing Containers</span></a></h2><h3 id="containers-00-00-00-17" tabindex="-1"><a class="header-anchor" href="#containers-00-00-00-17"><span>Containers 00:00-00:17</span></a></h3><p>In this demo, we&#39;re going to look at managing containers on a system. If we leave exited containers on a system, that can fill hard disk space quickly. There may also be times when we need to inspect containers for configurations.</p><h3 id="inspect-containers-00-17-02-27" tabindex="-1"><a class="header-anchor" href="#inspect-containers-00-17-02-27"><span>Inspect Containers 00:17-02:27</span></a></h3><p>Let&#39;s run docker images. This system doesn&#39;t have any images ready to work with. Let&#39;s pull an nginx image. Nginx is a webserver. This image will install a container that will run a webserver for my system. We need to inspect the image to see which port the webserver will run on.</p><p>The docker inspect command can provide detailed information about the properties of a docker image. Let&#39;s run docker image inspect nginx. This brings up a lot of information. We can use the <code>-f</code> option to search for a field of information, similar to the grep command. Let&#39;s type <code>docker image inspect nginx -f &#39;{{ .ContainerConfig.ExposedPorts }}&#39;</code> The inspect command defaults to searching and displaying in JSON arrays. We&#39;re searching the image for a container configuration that will show us which port is exposed for any containers built from the image. We see that this is a regular nginx installation that defaults to port 80, http traffic.</p><p>To make this webserver container operational, we need to start the container and provide a bridge between it and the physical system. To do this, we run <code>docker run --name nginx-test -d -P nginx</code>. The <code>-d</code> option runs the container in the background. The <code>-P</code> option will publish all exposed ports to random ports. This means that port 80 on my container will bridge to a random port on my system. When users try to access the webserver, they&#39;ll access my system IP address and the randomly generated port number. My system will take traffic on that port number and pass it to the container on port 80.</p><p>First, run ip a and get the IP address of the system. Then open a web browser and navigate to that IP. We see that nothing loads. Let&#39;s run <code>docker ps -a</code> to view which port number was assigned to the nginx container. We&#39;ll add the port number to the address bar, and we see the nginx landing page.</p><h3 id="build-images-02-27-04-07" tabindex="-1"><a class="header-anchor" href="#build-images-02-27-04-07"><span>Build Images 02:27-04:07</span></a></h3><p>Okay, now let&#39;s talk about building images. It&#39;s a useful option, but it can bloat the size of containers. It&#39;s more common to create a build file that will take a base OS image and run commands and other instructions to create the image.</p><p>Let&#39;s make a directory named build_test and cd into it. Next, create a build file that&#39;s named Dockerfile and enter a text editor. You begin by adding comments detailing your commands. Type #set the base image. On a new line, enter FROM in all caps and ubuntu in lowercase.</p><p>The next line will have #author, and we&#39;ll enter MAINTAINER TestOut on another line. You would type your own name or your company&#39;s name for the author. Next, we add <code>#Metadata</code>. Then type <code>LABEL version=&quot;1.0&quot;&#39;</code> and <code>LABEL description=&quot;Building an image with a Dockerfile&quot;</code> on separate lines. Lastly, we&#39;ll add a comment detailing package management. Then type RUN apt clean, RUN apt update, and RUN <code>apt install cowsay -y</code> on separate lines. Once that&#39;s done, write the file and exit the editor. Our build file is ready.</p><p>Now let&#39;s type <code>docker build -t jmacetestout/testout_image:cowsay</code> . The <code>-t</code> option allows us to tag the image to make it identifiable to other users. In order to properly tag an image, you must have a docker hub account to associate the tags with. Run docker images to see the newly built docker image listed.</p><h3 id="push-docker-images-04-07-04-45" tabindex="-1"><a class="header-anchor" href="#push-docker-images-04-07-04-45"><span>Push Docker Images 04:07-04:45</span></a></h3><p>The next step is to share images with others. The most common way to do this is to push the images to the online docker repository using the docker push command. You must have a docker hub account and be logged in to docker.</p><p>To log in to docker, run docker login and provide your login information. Once we&#39;re logged in, we can push the build image we just created with docker push and your docker hub usersname, then <code>/testout_image:cowsay</code>. The text after the forward slash (<code>/</code>) is the name you want to give the image. The text after the colon consists of tags that can be used to identify and quickly search for your image in the docker repository.</p><h3 id="clean-unused-containers-and-images-04-45-05-44" tabindex="-1"><a class="header-anchor" href="#clean-unused-containers-and-images-04-45-05-44"><span>Clean Unused Containers and Images 04:45-05:44</span></a></h3><p>Lastly, as we work, we&#39;ll want to remove containers and images that are no longer in use. To remove a container, it must be inactive or exited. If you want to remove an image, it must not have a container, active or inactive, loaded from it.</p><p>Let&#39;s list all our containers. We need to stop the nginx container with <code>docker stop nginx-test</code>. Now we can use the <code>docker rm</code> command to remove the container. Let&#39;s run <code>docker rm nginx-test</code>. When we run <code>docker ps -a</code> again, we see that all containers are removed.</p><p>The command to remove images is similar to removing containers. Let&#39;s run docker images. We see three images pulled to our system: our new build image, nginx, and ubuntu. To remove these images, we&#39;ll run docker rmi and the image ID of our custom build image, nginx ubuntu. When we run docker images again, we can see that all images have been removed.</p><h3 id="summary-05-44-06-04" tabindex="-1"><a class="header-anchor" href="#summary-05-44-06-04"><span>Summary 05:44-06:04</span></a></h3><p>And that&#39;s all for this demo on managing containers. We discussed how to inspect docker images, publish ports within a container, build custom images with a Dockerfile script, push images to the docker repository, and remove unnecessary containers and images from a system.</p><h2 id="_13-4-4-container-facts" tabindex="-1"><a class="header-anchor" href="#_13-4-4-container-facts"><span>13.4.4 Container Facts</span></a></h2><p>This lesson covers the following topics:</p><ul><li>Virtual machines vs. containers</li><li>Container management</li><li>Container image operations</li><li>Summarizing orchestration concepts</li></ul><h3 id="virtual-machines-vs-containers" tabindex="-1"><a class="header-anchor" href="#virtual-machines-vs-containers"><span>Virtual Machines vs. Containers</span></a></h3><p>Containers are a way to run programs in a virtual environment. Containers include all the files, libraries, and even any necessary operating system files that might be needed, bundled into one package. Containers use the same principle as virtual machines. They are installed on top of the operating system with an abstraction layer to share resources between the hardware and the containers.</p><p>The following table lists common terms you should be familiar with when working with containers:</p><table><thead><tr><th>Term</th><th>Definition</th></tr></thead><tbody><tr><td>Virtual machine</td><td> A virtual machine uses physical resources like the CPU, memory, and hard drive to run an operating system from within its host. </td></tr><tr><td>Hypervisor</td><td> On a server, the hypervisor is installed on top of the hardware of a server and virtualizes all the hardware resources to different clients in the form of an operating system. </td></tr><tr><td>Container engine</td><td> Instead of installing the hypervisor on top of the hardware, the container engine is installed on top of the host operating system. This allows the containers to use the resources from the host operating system. </td></tr><tr><td>Container</td><td> An application isolated in a lightweight package that allows the user to use the program similar to how you would use a virtual machine. </td></tr><tr><td>Container management</td><td> Because of their size, many individual containers can exist on one operating system. To help manage these containers, you can use either Docker or Podman. </td></tr></tbody></table><h3 id="container-management" tabindex="-1"><a class="header-anchor" href="#container-management"><span>Container Management</span></a></h3><p>Containers are managed by software, much like a hypervisor manages virtual machines. Docker and Podman are two popular solutions.</p><h3 id="docker" tabindex="-1"><a class="header-anchor" href="#docker"><span>Docker:</span></a></h3><p>Docker is a lightweight package that was created by Docker Inc. and released as open source. Docker runs on top of a host system, such as Linux. Some facts about Docker and managing Docker are:</p><ul><li>Docker runs as the root user.</li><li>Docker is used to build and manage container images.</li><li> Docker is monolithic in architecture, meaning that it is independent and self-contained. </li><li> Once a container is deployed in Docker, it can be stopped and started by using the <b class="fw-bold">docker start</b> and <b class="fw-bold">docker stop</b> commands. </li><li> To inspect and gather detailed information about a container in Docker, use the <b class="fw-bold">docker inspect</b> command. This command will produce a lot of information. It&#39;s recommended to output the contents and use <b class="fw-bold">grep</b> to inspect the information. </li><li> To list all the containers in Docker, use the <b class="fw-bold">docker ps</b> command. This command will list contents in columns and will include, container ID, name of image, command used to start container, when the container was started, current status of container, ports used, and name. </li><li> Docker images are deployed using the command: <b class="fw-bold">docker run -name</b><i class="fs-italicize">NAME</i> <b class="fw-bold">-p</b><i class="fs-italicize">PORTS IMAGE.</i> NAME is the name of the container, PORTS is the port your want to expose, IMAGE is the name of the image. </li><li> Connecting to running containers is done by using the <b class="fw-bold">docker exec</b> command in the Docker image. Type <b class="fw-bold">exit</b> to break the connection. </li><li> To view logs of a container, use the <b class="fw-bold">docker log</b> command. </li></ul><h3 id="podman" tabindex="-1"><a class="header-anchor" href="#podman"><span>Podman:</span></a></h3><p>Podman is a tool and is considered daemonless, which is the main difference from Docker. It is open-source that is used to find, run, build, share, and deploy applications on Linux systems. Some facts about Podman are:</p><ul><li>Podman can run rootless.</li><li> Podman can not be used to build images. A separate tool called Buildah is needed. Another tool, Skopeo, moves container images between different types of storage systems. </li><li>Podman is modular.</li><li>Podman uses a command line interface.</li></ul><h3 id="container-image-operations" tabindex="-1"><a class="header-anchor" href="#container-image-operations"><span>Container Image Operations</span></a></h3><p>You are able to build and create your own images. You can also find existing container images in repositories . When working with your images, you will use operations to store and retrieve images. Keep in mind the following facts about container image operations.</p><ul><li> To build your own Docker image, you can use a Dockerfile. A Dockerfile is a text file that has instructions that tell Docker what to do when creating an image. The text file will detail the parent image and initial state where it should start. It will contains metadata about the author and properties of the image. Will contain the commands to run during the build. Specify details about the image that will be created. </li><li> When you want an image to be stored in a repository, you <b class="fw-bold">push</b> the image. Pushing an image is the process of copying it from your local machine to the repository. Pushing can be done from a command line or from a program designed to do so. Images are often tagged with the latest version during the push process. </li><li> Pulling an image is the reverse process of pushing. You <b class="fw-bold">pull</b> an image when you want to bring the current version to your local machine. </li><li> To view a list of Docker images on your system, use the <b class="fw-bold">docker images</b> command or <b class="fw-bold">docker image ls</b> command. </li><li> You can remove Docker images with the <b class="fw-bold">docker rmi</b> command. </li></ul><h3 id="summarizing-orchestration-concepts" tabindex="-1"><a class="header-anchor" href="#summarizing-orchestration-concepts"><span>Summarizing Orchestration Concepts</span></a></h3><p>As a review, containers are a way to run programs in a virtual environment. Containers include all the files, libraries, and even any necessary operating system files that might be needed, bundled into one package. Once you have many containers, you need a way to manage them. This is where the term orchestration comes in. Container orchestration is the process of automating, managing, scaling, and networking containers. There are several orchestration engines that can be used for this, including Docker Swarm, Apache Mesos, and Kubernetes. It&#39;s important to note that sometimes automation and orchestration are confused with each others. Automation is typically used to automate a single task to reduce the manual interaction by a human. Orchestration is the process of automating processes and workflows that involves many different tasks and many different systems.</p><p>The following table lists and compares some of these orchestration engines:</p><table><thead><tr><th>Orchestration Engine</th><th>Concepts</th></tr></thead><tbody><tr><td width="151">Kubernetes</td><td width="1384"> Kubernetes is an open-source orchestration system. Kubernetes was originally created by Google, but is now maintained by the Cloud Native Computing Foundation. Most consider Kubernetes the gold standard in orchestration systems. Below are some facts about Kubernetes. <ul><li>Works with Docker, Containerd, and CRI-O.</li><li> Monitors the health of containers and responds if the containers are not responding or performing poorly. </li><li>Can run multiple containers at the same time.</li><li>Works with on-premises or cloud systems.</li><li>Can by used for load balancing.</li><li> Is highly scalable, meaning that you can add more containers if needed. </li><li> Can be used to manage updates, including rolling back updates. </li></ul><p>Several key concepts used by Kubernetes are:</p><ul><li> With Kubernetes, you can use what are referred to as <i class="fs-italicize">pods</i> . Pods are a group of containers when resources are shared. The shared recourse could be something like a storage pool. The pods are all able to access the same storage. </li><li> Using the above storage example, if you need to make changes to the storage, you can use just one of the Kubernetes containers in the pod to do so. This container is referred to as a <i class="fs-italicize">sidecar</i> . </li><li> Sidecars are containers used to perform a task on behalf of other containers. We can refer to this sidecar as an <i class="fs-italicize">Ambassador containe</i> r, meaning that this container is sort of the spokesperson for all the containers in the pod. Remember, we want containers to focus on one task, so having a dedicated container to perform tasks such as communication with other containers is considered best practice. </li><li> We know that containers are used typically to perform one task. Sometimes, to perform a series of tasks requirement multiple containers, each doing something different. When these containers are combined into pods, this is referred to as <i class="fs-italicize">microservices</i> . When microsservices need to work together, it&#39;s referred to as a <i class="fs-italicize">service mesh</i> . Finally, the service mesh is established by using sidecars. </li></ul></td></tr><tr><td width="151">Docker Swarm</td><td width="1384"> Docker Swarm is used to cluster Docker containers. In general, a swarm is to move something in large numbers. Docker Swarm: <ul><li>Is integrated with Docker.</li><li> Uses a command line interface to manage the containers in the swarm. </li><li>Allows scaling of the swarm.</li><li>Can be used for load balancing.</li><li>Allows for rolling out updates.</li></ul></td></tr><tr><td width="151">Apache Mesos</td><td width="1384"> Apache Mesos is used to manage computer clusters. Apache Mesos was developed by the University of Berkeley and is open source. Apache Mesos: <ul><li> Is a container management tool used to isolate CPU, memory, and file systems on Linux systems. </li><li>Can run Hadoop, Jenkins, Spark, Aurora, and other tools.</li><li> Is combined with Marathon to provide a more complete solution to orchestration. </li><li>Can be used to manage Docker containers.</li></ul></td></tr></tbody></table><p>We have summarized some of the specific features for orchestration engines. The following table lists other orchestration terms and concepts:</p><table><thead><tr><th>Term</th><th>Definition</th></tr></thead><tbody><tr><td width="151">Single-node and multi-node uses</td><td width="1384"> With Kubernetes, you use pods to combine containers to work together to handle tasks as we scale. A use case example of when this happens is a website that handles all the web traffic for your business. One day, your business becomes very popular, and you need to add more containers to handle the traffic. This is a simple example of when we went from having a single container, or node, to a pod of containers (multi-node). </td></tr><tr><td width="151">Container persistent storage</td><td width="1384"> In general, persistent storage is a physical storage on a device such as a traditional hard drive or a solid-state drive. It is called persistent because the data on the devices is retained if the devices lose power. By default, containers do not save the data that they produce. When a container loses power, the data is lost, so this is a major concern for containers that need to store data. When containers need to store data, they have to be configured to store the data on a back-end storage system. These systems can be local storage that are mounted. The underlining devices can be a variety of solutions, such as traditional sata drives, solid-state drives, RAID arrays, or storage area networks. </td></tr><tr><td width="151">Container networks</td><td width="1384"> Traditional methods of networking involves having a network card on a device that communicates with other nodes on a network or the internet. Containers and the applications that run on them will most often need access to the network or to the internet. With containers, networks work a bit differently than traditional networking. A few key container networking concepts are: <ul><li> Overlay networks work by using tunnels to talk to other containers on a network. This will allow containers to function as if they are located on the same host. </li><li> Bridging is the establishment of different network segments together. This is typically done by directing traffic through routers. But with bridging, the segments are merged into a single segment. There are different types of bridging: simple bridging merges two segments, multiport merges multiple networks, transparent bridging builds routing tables, and source route builds route based on the source. </li><li> Network address translation (NAT) is the process of translating private IP addresses into public IP addresses. This concept is no different than how it is done traditionally. Some of the types of NAT used with container networking are DNAT, SNAT, and Masquerade NAT. </li><ul><li> DNAT, or destination NAT, is used when servers are behind firewalls, and you want to access them from the internet. </li><li> SNAT, or source NAT, is used when internal networks are using statically assigned IP addresses. Traffic is directed to the internet through device with a access to the internet. </li><li> Masquerade Nat is used in internal networks with dynamic IP addressing. Traffic to the public internet is directed through a single device. </li></ul><li> Often times, your container will only need to communicate with the host that it resides on. If outside communication is needed to reach the container, it will be configured to flow through the host through a virtual network connection. </li></ul></td></tr><tr><td width="151">Bootstrapping</td><td width="1384"> Bootstrapping is the process to self-start without assistance. In computing, the term <i class="fs-italicize">booting</i> refers to a system starting up when it receives power via the bootloader code. Bootstrapping refers to installing a new system from an image or configuration from an existing system through automation. A tool that can be used to do this is called Cloud-int. Cloud-int can be used to configure networking, run scripts, and other tasks. </td></tr><tr><td width="151">Container registries</td><td width="1384"> Container registries or container repositories are a central location where container images are stored. Examples are Docker Hub, Amazon ECR, Harbor, GitHub Container Registry, and Google Container Registry. </td></tr></tbody></table>',100)]))}const c=t(o,[["render",s],["__file","04.html.vue"]]),d=JSON.parse('{"path":"/13/04.html","title":"Section 13.4 Containers","lang":"zh-CN","frontmatter":{"lang":"zh-CN","title":"Section 13.4 Containers","description":"some description"},"headers":[{"level":2,"title":"13.4.1 Containers on Linux","slug":"_13-4-1-containers-on-linux","link":"#_13-4-1-containers-on-linux","children":[]},{"level":2,"title":"13.4.2 Using Containers","slug":"_13-4-2-using-containers","link":"#_13-4-2-using-containers","children":[{"level":3,"title":"Containers 00:00-00:32","slug":"containers-00-00-00-32","link":"#containers-00-00-00-32","children":[]},{"level":3,"title":"Docker Images 00:32-01:20","slug":"docker-images-00-32-01-20","link":"#docker-images-00-32-01-20","children":[]},{"level":3,"title":"Docker Containers 01:20-02:40","slug":"docker-containers-01-20-02-40","link":"#docker-containers-01-20-02-40","children":[]},{"level":3,"title":"Connecting to Containers 02:40-04:13","slug":"connecting-to-containers-02-40-04-13","link":"#connecting-to-containers-02-40-04-13","children":[]},{"level":3,"title":"Creating Images 04:13-05:28","slug":"creating-images-04-13-05-28","link":"#creating-images-04-13-05-28","children":[]},{"level":3,"title":"Logging in Containers 05:28-05:55","slug":"logging-in-containers-05-28-05-55","link":"#logging-in-containers-05-28-05-55","children":[]},{"level":3,"title":"Stopping Containers 05:55-06:14","slug":"stopping-containers-05-55-06-14","link":"#stopping-containers-05-55-06-14","children":[]},{"level":3,"title":"Summary 06:14-06:23","slug":"summary-06-14-06-23","link":"#summary-06-14-06-23","children":[]}]},{"level":2,"title":"13.4.3 Managing Containers","slug":"_13-4-3-managing-containers","link":"#_13-4-3-managing-containers","children":[{"level":3,"title":"Containers 00:00-00:17","slug":"containers-00-00-00-17","link":"#containers-00-00-00-17","children":[]},{"level":3,"title":"Inspect Containers 00:17-02:27","slug":"inspect-containers-00-17-02-27","link":"#inspect-containers-00-17-02-27","children":[]},{"level":3,"title":"Build Images 02:27-04:07","slug":"build-images-02-27-04-07","link":"#build-images-02-27-04-07","children":[]},{"level":3,"title":"Push Docker Images 04:07-04:45","slug":"push-docker-images-04-07-04-45","link":"#push-docker-images-04-07-04-45","children":[]},{"level":3,"title":"Clean Unused Containers and Images 04:45-05:44","slug":"clean-unused-containers-and-images-04-45-05-44","link":"#clean-unused-containers-and-images-04-45-05-44","children":[]},{"level":3,"title":"Summary 05:44-06:04","slug":"summary-05-44-06-04","link":"#summary-05-44-06-04","children":[]}]},{"level":2,"title":"13.4.4 Container Facts","slug":"_13-4-4-container-facts","link":"#_13-4-4-container-facts","children":[{"level":3,"title":"Virtual Machines vs. Containers","slug":"virtual-machines-vs-containers","link":"#virtual-machines-vs-containers","children":[]},{"level":3,"title":"Container Management","slug":"container-management","link":"#container-management","children":[]},{"level":3,"title":"Docker:","slug":"docker","link":"#docker","children":[]},{"level":3,"title":"Podman:","slug":"podman","link":"#podman","children":[]},{"level":3,"title":"Container Image Operations","slug":"container-image-operations","link":"#container-image-operations","children":[]},{"level":3,"title":"Summarizing Orchestration Concepts","slug":"summarizing-orchestration-concepts","link":"#summarizing-orchestration-concepts","children":[]}]}],"git":{"updatedTime":1736836195000},"filePathRelative":"13/04.md"}');export{c as comp,d as data};
